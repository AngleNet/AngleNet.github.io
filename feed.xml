<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Angle Net</title>
		<description>Software Developer</description>
		<link>https://anglenet.github.io/</link>
		<atom:link href="https://anglenet.github.io//feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Python Interpreter Internals</title>
				<description>&lt;h3 id=&quot;internals&quot;&gt;Internals&lt;/h3&gt;

&lt;h4 id=&quot;gil&quot;&gt;GIL&lt;/h4&gt;

&lt;p&gt;If you worked along with python and C ever, you may familiar with it. The mechanism used by the CPython interpreter to assure that only one thread executes Python bytecode at a time. This simplifies the CPython implementation by making the object model (including critical built-in types such as dict) implicitly safe against concurrent access. Locking the entire interpreter makes it easier for the interpreter to be multi-threaded, at the expense of much of the parallelism afforded by multi-processor machines.&lt;/p&gt;

&lt;p&gt;GIL must be held by the current thread before it can safely access Python objects. The interpreter regularly tries to switch threads. The lock is also released around potential blocking I/O operations.&lt;/p&gt;

&lt;h3 id=&quot;about-reading-cpython-source-code&quot;&gt;About reading Cpython source code&lt;/h3&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://docs.python.org/3/c-api/index.html&quot;&gt;Official Python/C API references&lt;/a&gt;&lt;/p&gt;

    &lt;p&gt;It explains much concepts used in the Cpython implementation and why they doing it that way.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Fri, 14 Oct 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/10/Python-Interpreter</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/10/Python-Interpreter</guid>
			</item>
		
			<item>
				<title>JVM Stuffs</title>
				<description>&lt;h4 id=&quot;auto-garbage-collectors&quot;&gt;Auto garbage collectors&lt;/h4&gt;

&lt;p&gt;This is just a overview of GCs in HotSpot now. Java’s GC is generation based since we need to eliminate those short lived objects as soon as possible to get more memory efficiency. When Java calls GC, it will stop the world to check each object’s reference count. The memory model just looks like the following:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blogs/GC-internals.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are 5 GCs in HotSpot, they are Serial GC, Parallel GC, Parallel GC, Concurrent mark &amp;amp; sweep GC and Garbage first GC. In parallel GC, multiple threads are used to speed up GC. So it’s also called throughput GC. But it has fragmentation effect (Each garbage collection thread involved in a minor collection reserves a part of the tenured generation for promotions and the division of the available space into these “promotion buffers” can cause a fragmentation effect). CMS GC does most of the garbage collection work concurrently with the application threads. Also called responsive gc. There is no compaction here. The Concurrent Mark Sweep (CMS) collector is designed for applications that prefer shorter garbage collection pauses and that can afford to share processor resources with the garbage collector while the application is running.&lt;/p&gt;

&lt;h5 id=&quot;emsp-resources&quot;&gt;  Resources&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html&quot;&gt;Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://blog.takipi.com/7-things-you-thought-you-knew-about-garbage-collection-and-are-totally-wrong/&quot;&gt;7 Things You Thought You Knew About Garbage Collection - and Are Totally Wrong&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html&quot;&gt;Good GC introduction&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Fri, 14 Oct 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/10/JVM</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/10/JVM</guid>
			</item>
		
			<item>
				<title>Classifier</title>
				<description>&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;
&lt;p&gt;We use Machine Learning as a powerful tool to dicover patterns and make predictions. Model and statistics help us understand the “pattern”. Optimization algorithm learns the “pattern”. The most important part is data. Data drives everything else.
There are mainly 3 types of classifier, i.e Observer based, Generative model and Discriminative model. KNN is based on all of the instances. Bayes networks are generative model and decision trees are discriminative model. Also, I will explain some linear classification algorithms, I think that is the most interesting part of this blog.&lt;/p&gt;

&lt;h3 id=&quot;k-nearst-neighbor&quot;&gt;K-Nearst Neighbor&lt;/h3&gt;

&lt;h3 id=&quot;bayes-networks&quot;&gt;Bayes Networks&lt;/h3&gt;

&lt;h3 id=&quot;dicision-tree&quot;&gt;Dicision Tree&lt;/h3&gt;

&lt;h3 id=&quot;linear-classifiers&quot;&gt;Linear Classifiers&lt;/h3&gt;

&lt;p&gt;Linear classifier should divide the input space into a collection of regions via some hyperplanes since there may be multiple classes in the input space.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Find the Linear Boundaries&lt;/p&gt;

    &lt;p&gt;1.Fit linear regression model to the class indicator variables, then the overlapping margin is what we want.So:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\lbrace X:(\beta _{k0} - \beta_{l0}) + (\beta _{k} - \beta _{l})X = 0\rbrace&lt;/script&gt;

    &lt;p&gt;We will get the linear boundary.&lt;/p&gt;

    &lt;p&gt;2.Directly model the boundaries between the classes as linear seperating hyperplanes&lt;/p&gt;

    &lt;p&gt;(d-1) dimensional hyperplanes(Also called perceptron):&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\lbrace X:\beta _0 + \beta _1 X_1 + \beta _2 X_2 = 0 \rbrace&lt;/script&gt;

    &lt;p&gt;We define the boundary as:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\lbrace \beta _0 + \beta ^TX = 0\rbrace&lt;/script&gt;

    &lt;p&gt;For every point $X_0$ in the sample space, the distance from $X_0$ to the hyperplane is:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;d(\beta _0, \beta) = {\beta ^T(X - X_0) \over ||\beta||}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Perceptron Learning Algorithm&lt;/p&gt;

    &lt;p&gt;Idea: Minimize the risk of misclassification.
  I want the hyperplane could seperate as much samples as possible. Any mistake should hurt the objective function. So I define a risk function as:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin \quad R(\beta _0, \beta) = \sum_{X \in M}L(\beta _0, \beta, X_i, y_i)&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
where\; L(\beta _0, \beta, X_i, y_i) = \begin{cases}0, &amp; \text{if  $y_i(\beta _0 + \beta ^TX) \ge 0$}  \\ -y_i(\beta _0 + \beta ^TX) &amp; \text{otherwise} \end{cases} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Where $M$ is the set of misclassified samples. There are two ways to solve this: Gradient descent and Stochastic gradient descent. I’m not going to talk about this here. If you are interested, step to &lt;a href=&quot;http://sebastianruder.com/optimizing-gradient-descent/&quot;&gt;Overview of gradient descent including popular frameworks&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Maximum Margin Classifier&lt;/p&gt;

    &lt;p&gt;Idea: Find the largest isolation band that seperates the classes. We hope that a classifier that has a large margin on the training data will also have a large margin on the test data. When the feature dimension is too large, it’s easy to get overfitting.&lt;/p&gt;

    &lt;p&gt;Then we get this:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmax _{(\beta,\; \beta _0)} \quad M&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;s.t.\quad {y_i(X_i^T \beta+\beta _0) \over ||\beta||} \ge M&lt;/script&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;When we set $M$ to ${1 \over&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;\beta&lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;}$, we get:&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin _{(\beta,\; \beta _0)} \quad ||\beta||&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;s.t.\quad y_i(X_i^T \beta+\beta _0) \ge 1&lt;/script&gt;

    &lt;p&gt;We can do better:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin _{(\beta,\; \beta _0)} \quad {1 \over 2}||\beta||^2&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;s.t.\quad y_i(X_i^T \beta+\beta _0) \ge 1&lt;/script&gt;

    &lt;p&gt;It is a linear programming prolem. We solve this via Lagrangian Multiplier. The Lagrange function to be minimized w.r.t $\beta$ and $\beta _0$, is:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;Lp = {1 \over 2} ||\beta||^2 - \sum_{i=1}^N\alpha _i[y_i(x_i^T\beta + \beta _0) - 1]&lt;/script&gt;

    &lt;p&gt;Setting the derivatives to zero, we obtain:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\beta = \sum_{i=1}^N\alpha _i y_i x_i&lt;/script&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;0 = \sum_{i=1}^N \alpha _i y_i&lt;/script&gt;

    &lt;p&gt;We will try to solve this here.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Some Background
        &lt;ol&gt;
          &lt;li&gt;Lagrange Dual&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin \quad f_D(x)&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
s.t. \quad \begin{cases} f_i(x) \le 0 &amp; i = 1, ..., m \\ h_i(x) = 0 &amp;i = 1, ..., p\end{cases} %]]&gt;&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m\lambda _i f_i(x) + \sum_{i=1}^p \nu h_i(x)&lt;/script&gt;

        &lt;ol&gt;
          &lt;li&gt;Lagrange dual function&lt;/li&gt;
        &lt;/ol&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;g(\lambda, \nu) = \inf_{X \in D}L(X, \lambda, \nu)&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmin \quad L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m\lambda _i f_i(x) + \sum_{i=1}^p \nu h_i(x)&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;where \quad \lambda \gt 0&lt;/script&gt;

        &lt;p&gt;Displeasure part:&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;f_i(x) \ge 0&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;h_i(x) \ne 0&lt;/script&gt;

        &lt;p&gt;Our displeasure grows as the constraint becomes “more violate”. Here the great idea is that “Replacing hard constrains with soft versions”.&lt;/p&gt;

        &lt;ol&gt;
          &lt;li&gt;Conjugate function&lt;/li&gt;
        &lt;/ol&gt;

        &lt;p&gt;The conjugate function $f^*(y)$ is the maximum gap between the linear function $xy$ and $f(x)$. See Convex Optimization by Stephen Boyd Chapter 3.3&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Solving details&lt;/p&gt;

        &lt;p&gt;Get Wolfe dual: &lt;a href=&quot;https://www.cs.rochester.edu/~gildea/2013_Spring/wolfe.pdf&quot;&gt;Wolfe Dual Explaination&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/pdf/1506.04574.pdf&quot;&gt;Paper about lagrange and Wolf dual functions&lt;/a&gt;&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;argmax \quad L_D = \sum_{i=1}^N\alpha _i - {1 \over 2}\sum_{i=1}^N\sum_{k=1}^N\alpha _i \alpha _k y_i y_k x_i^T x_k&lt;/script&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;s.t. \quad \alpha _i \ge 0 \; \text{and} \; {dL \over dx} = 0&lt;/script&gt;

        &lt;p&gt;The solution is obtained by maxmizing $L_D$ in the positive orthant.  A simpler convex optimization problem. Here the tricky part is we need to maxmizing $L_D$. That is because $L_D(\alpha)$ is a concave function.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Classifier&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Machine&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 13 Oct 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/10/ML-Classifier</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/10/ML-Classifier</guid>
			</item>
		
			<item>
				<title>MapReduce Framework</title>
				<description>&lt;h3 id=&quot;architecture&quot;&gt;Architecture&lt;/h3&gt;

</description>
				<pubDate>Fri, 15 Apr 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/04/DS-MapReduce-1</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/04/DS-MapReduce-1</guid>
			</item>
		
			<item>
				<title>Go Language Notes</title>
				<description>&lt;h3 id=&quot;confusing-language-blocks&quot;&gt;1. Confusing Language blocks&lt;/h3&gt;

&lt;h4 id=&quot;interface&quot;&gt;1.1 Interface&lt;/h4&gt;

&lt;p&gt;Come soon&lt;/p&gt;

&lt;h4 id=&quot;channel&quot;&gt;1.2 Channel&lt;/h4&gt;

&lt;p&gt;Come soon&lt;/p&gt;

&lt;h4 id=&quot;make-vs-new&quot;&gt;1.3 &lt;code&gt;make&lt;/code&gt; VS &lt;code&gt;new&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;According to the &lt;a href=&quot;https://golang.org/doc/effective_go.html#allocation_new&quot;&gt;Official explanation&lt;/a&gt;, &lt;code&gt;new&lt;/code&gt; does not initialize the memory, only zeros it and return the address. &lt;code&gt;make(T, args)&lt;/code&gt; serves a purpose different from new(T). It creates slices, maps, and channels only, and it returns an initialized (not zeroed) value of type T (not *T). So what &lt;code&gt;make&lt;/code&gt; returns is usable immediately while what &lt;code&gt;new&lt;/code&gt; returns needs further initializing if zeroed content can not be used.&lt;/p&gt;

&lt;h3 id=&quot;go-idioms&quot;&gt;2. Go idioms&lt;/h3&gt;

&lt;h4 id=&quot;atomic-operation&quot;&gt;2.1 Atomic operation&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;	countCh := make(chan int)
    count := &amp;lt;- countCh
    count++
    countCh &amp;lt;- count
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;check-whether-the-channel-is-full&quot;&gt;2.2 Check whether the channel is full&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;	if len(ch) == cap(ch){
    }else{
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;useful-links&quot;&gt;Useful Links&lt;/h3&gt;

&lt;p&gt;The official &lt;a href=&quot;https://golang.org/doc/effective_go.html&quot;&gt;Effective go&lt;/a&gt; is the best place to conquer the confusion of language specifics.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang&quot;&gt;50 shades of Go: traps and pitfalls&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.nada.kth.se/~snilsson/concurrency/&quot;&gt;Concurrency&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rogpeppe.wordpress.com/&quot;&gt;Rogpeppe Page&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Tue, 29 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/go-notes</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/go-notes</guid>
			</item>
		
			<item>
				<title>RE<sub></sub>--Useful Links</title>
				<description>&lt;h3 id=&quot;course-ware&quot;&gt;Course Ware&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.fsu.edu/~redwood/OffensiveSecurity/lectures.html&quot;&gt;Offensive Course&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Sun, 27 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/RE-2</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/RE-2</guid>
			</item>
		
			<item>
				<title>OS<sub>2</sub>--Device Driver</title>
				<description>&lt;h3 id=&quot;development-environment&quot;&gt;1. Development Environment&lt;/h3&gt;

&lt;p&gt;Before coding, almost the most important thing is to get surpport code running. Sometimes it is not such easy to get everything right. This is the case. The trouble just comes. The following is my solution:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;run &lt;code&gt;vagrant init ubuntu/trusty64 &amp;amp;&amp;amp; vagrant up --provider virtualbox&lt;/code&gt; to provide a clean environment for me. And &lt;a href=&quot;https://atlas.hashicorp.com/boxes/search&quot;&gt;Atlas&lt;/a&gt; is a nice place to search your appropriate boxes.&lt;/li&gt;
  &lt;li&gt;run update.sh, it will update all surpport code with the official release.&lt;/li&gt;
  &lt;li&gt;download &lt;a href=&quot;http://download.simics.net/pub/simics/4.8_fcd175/&quot;&gt;simics&lt;/a&gt;. The simics forum is a good place.&lt;/li&gt;
  &lt;li&gt;run &lt;code&gt;apt-get install mtools&lt;/code&gt; to access utilities of MS-DOS on linux.&lt;/li&gt;
  &lt;li&gt;Till now, we compiles the surpport code and generates the boot image.&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 24 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/Operating-system-2</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/Operating-system-2</guid>
			</item>
		
			<item>
				<title>DS<sub>1</sub>--Warm Up</title>
				<description>&lt;h3 id=&quot;environment-setup&quot;&gt;1. Environment Setup&lt;/h3&gt;

&lt;p&gt;You only need to install &lt;code&gt;go&lt;/code&gt; compiler. Just run the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install gccgo-5 to install gccgo 1.4.2.
go test to run tests.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Official installation is recommended.
### Useful links&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cse.buffalo.edu/~stevko/courses/cse486/spring13/practice_problems.html&quot;&gt;Good Homeworks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://golang.org/doc/effective_go.html&quot;&gt;Effective Go&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
				<pubDate>Thu, 24 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/DS-1</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/DS-1</guid>
			</item>
		
			<item>
				<title>DB<sub>1</sub>--Warm Up</title>
				<description>&lt;h3 id=&quot;course-notes&quot;&gt;1. Course Notes&lt;/h3&gt;

&lt;h3 id=&quot;project-notes&quot;&gt;2. Project Notes&lt;/h3&gt;

</description>
				<pubDate>Sun, 20 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/DB-1</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/DB-1</guid>
			</item>
		
			<item>
				<title>RE<sub>1</sub>--Warm Up</title>
				<description>
</description>
				<pubDate>Sun, 20 Mar 2016 00:00:00 +0800</pubDate>
				<link>https://anglenet.github.io//2016/03/SE-1</link>
				<guid isPermaLink="true">https://anglenet.github.io//2016/03/SE-1</guid>
			</item>
		
	</channel>
</rss>
